@startuml class_rl

enum RLTypes {
    ANY
    DISCRETE
    CONTINUOUS
}


class WorkerRun {
    env : EnvRun
    on_reset(env)
    policy() : action
    on_step()
    render()
    state_encode(env_state) : rl_state
    action_encode(env_action) : rl_action
}
note "Keeps run-time state.\nAbsorbs the difference with the environment." as WorkerRunMemo
WorkerRun . WorkerRunMemo


abstract RLWorker {
    config : RLConfig
    parameter : RLParameter
    memory : <color red>IRLMemoryWorker</color>
    on_reset(worker_run, env_run)
    policy()
    on_step()
    render_terminal()
    render_rgb_array()
}
RLWorker -- WorkerRun


abstract AlgorithmRLWorker {
    call_on_reset()
    call_policy()
    call_on_step()
}
AlgorithmRLWorker -- RLWorker

note as AlgorithmRLWorkerMemo
Arguments modified by implementation algorithm
- DiscreteActionWorker
- ContinuousActionWorker
- etc..
end note
AlgorithmRLWorker <|- AlgorithmRLWorkerMemo


abstract RLTrainer {
    config : RLConfig
    parameter : RLParameter
    memory : <color red>IRLMemoryTrainer</color>
    train()
    train_on_batchs()
}
note as RLTrainerMemo
Use memory only for train,
implement train_on_batchs for other processes
end note
RLTrainer <|-- RLTrainerMemo


abstract RLMemory {
    config : RLConfig
    .. <color red>IRLMemoryWorker</color> ..
    add()
    .. <color red>IRLMemoryTrainer</color> ..
    is_warmup_needed()
    sample()
    update()
    .. other ..
    backup()
    restore()
}


abstract RLParameter {
    config : RLConfig
    length() : int
    restore()
    backup()
}


abstract RLConfig {
    getName() : str
    get_use_framework() : str
    base_action_type : RLTypes
    base_observation_type : RLTypes
}


RLTypes .. RLConfig

RLConfig --- RLWorker
RLConfig --- RLTrainer
RLConfig -- RLParameter
RLConfig -- RLMemory

RLParameter -- RLWorker
RLParameter -- RLTrainer
RLMemory -- RLWorker
RLMemory -- RLTrainer

@enduml