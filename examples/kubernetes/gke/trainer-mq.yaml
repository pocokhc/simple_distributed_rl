apiVersion: v1
kind: Service
metadata:
  name: mq-internal-service
spec:
  type: ClusterIP
  selector:
    app: trainer
  ports:
  - name: mq-internal-port
    protocol: TCP
    port: 5672
    targetPort: 5672

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: trainer
spec:
  replicas: 1
  selector:
    matchLabels:
      app: trainer
  template:
    metadata:
      labels:
        app: trainer
    spec:
      nodeSelector:
        cloud.google.com/gke-accelerator: nvidia-tesla-t4
      containers:
        # --- trainer ---
        - name: trainer-node
          #image: nvidia/cuda:11.0.3-runtime-ubuntu20.04
          image: {YOUR IMAGE}
          #command: ["sh", "-c", "while true; do sleep 3600; done"]
          command: ["python", "-u", "/code/server_trainer.py"]
          resources:
            requests:
              cpu: 10m
              memory: 256Mi
              nvidia.com/gpu: 1
            limits:
              cpu: 1
              memory: 32Gi
              nvidia.com/gpu: 1

        # --- RabbitMQ ---
        - name: rabbitmq
          image: rabbitmq:3-alpine
          ports:
            - containerPort: 5672
          env:
            - {"name": "RABBITMQ_DEFAULT_USER", "value": "guest"}
            - {"name": "RABBITMQ_DEFAULT_PASS", "value": "guest"}
          resources:
            requests:
              cpu: 10m
              memory: 128Mi
            limits:
              cpu: 1
              memory: 512Mi
